%% \begin{itemize}
%% \item Describe the task (list briefly its principles)
%% \item Give examples.
%% \end{itemize}
\input{figures/oie_examples}
The task of Open IE focuses on extracting stand-alone propositions (predicate and arguments tuples)
which are explicitly asserted by the sentence.
As opposed to traditional information extraction, it is not bounded by a predefined lexicon.
Table \ref{tab:oie_examples} depicts several example sentences and their respective Open IE extractions.

The original Open IE task definition lacked formal rigor,
subsequently inhibiting the creation of a large gold annotated resource
which often accompanies better defined tasks,
such as Penn Treebank \cite{ptb} for syntactic parsing or PropBank \cite{propbank} for semantic role labeling.
In spite of this, recent work \cite{bhutani2016nested,Stanovsky2016EMNLP} have managed
to identify several principles upon which the task has converged.
For instance, each extraction should be \emph{asserted} by the sentence -
e.g., not extracting \pred{won} as a stand-alone proposition in the first example in Table \ref{tab:oie_examples},
and \emph{minimal} - e.g., ``Barack Obama'' and ``a former U.S. president''
as separate arguments yielding two separate propositions in the second example.

%% \begin{itemize}
%% \item Prominent systems were made by following these principles.
%% \item These were found widely useful in a set of extrinsic tasks, while an intrinsic
%%   annotated corpora was not available until recently.
%% \item End with Open IE4 which used SRL as underlying representation
%% \end{itemize}

%% Thanks to its simple and useful representation, Open IE has gained consistent attention.
%% Various end applications have made use of it as an underlying representation for
%% different semantic tasks, such as knowledge base population
%% \cite{2015angeli-openie}, question answering \cite{fader2014open}, textual entailment \cite{Melamud:ACL13,Berant:ACL11}, summarization evaluation \cite{yang2016peak}, and more.

Significant effort was put in recent years in devising automatic Open IE extractors (many of
which made publicly available) following the principles
discussed above.
A couple of  early systems attempted distant supervision \cite{wu2010open,banko2007open}.
More recent attempts mostly apply a rule based approach, partly due to the lack of supervised annotations,
to extract predicate argument structures
as a post processing step over an underlying core NLP pipeline.
ReVerb \cite{fader2011identifying} extracts Open IE propositions from part of speech tags, while
OLLIE \cite{mausam2012open}, ClausIE \cite{del2013clausie} and PropS \cite{props2016} post-process dependency trees.
Recently, Open IE4 extracts tuples from Semantic Role Labeling (SRL) annotations.
These systems typically associate a confidence metric with each extraction
%indicating the degree with which the model believes this extraction is correct.
which allows end applications to choose a cut-off value, trading off precision and recall according
to their specific needs.


%% \begin{itemize}
%% \item OIE4 was able to convert from SRL since the tasks are related
%% \item List similarities with OIE4
%%   \begin{itemize}
%%   \item Isolates asserted propositions.
%%   \end{itemize}
%% \end{itemize}

Open IE4 is able to efficiently extract Open IE tuples from SRL thanks to
the close similarities between the two tasks.
Both SRL and Open IE aim to recover predicate-argument structures from sentences, extracting frames consisting
of a single predicate and a varying number of arguments.
Differently, SRL also identifies argument roles, but does not attempt
to identify minimal and asserted propositions, as Open IE does.
%% \begin{itemize}
%% \item Our EMNLP paper capitalizes on these similarities, and convert a specific variant of SRL - QA-SRL
%% \item This was shown to ``close the gap'' between SRL and OIE, and to subsume OIE
%% \item Following this observation they created a large OIE dataset (point to figure with stats)
%% \item This was composed of two domains: Newswire (from Penn Treebank) and Wikipedia
%% \item Following, they tested various OIE systems against it.
%% \item The best performing systems (OIE4, ClausIE, and Props) offered different tradeoff of precision and recall
%%   (point to figure)
%% \end{itemize}
Further capitalizing on the similarities between the two tasks, \newcite{Stanovsky2016EMNLP} found that QA-SRL \cite{hequestion}, a variant of traditional SRL, fully subsumes Open IE. In particular, they showed how assertedness and minimality \emph{can} be recovered from QA-SRL annotations. Consequently, they devised a high quality automatic conversion from the large hand-annotated QA-SRL bank to form the first
large, system-independent, annotated corpus for Open IE.
Since QA-SRL has annotated only verbal predicates, this Open IE corpus is also composed only of verbal predicates.
Overall the corpus is composed of 10359 extractions over 7710 predicates in 3200 sentences.


% Further capitalizing on these similarities between the two tasks, \newcite{Stanovsky2016EMNLP} have
% used QA-SRL \cite{hequestion}, a  variant of traditional SRL,  to ``close the gap'' between the tasks.
% Specifically, they showed that QA-SRL subsumes Open IE,
% and devised a high quality automatic conversion from the large hand-annotated QA-SRL bank to form the first
% large, system-independent resource for Open IE.
%The complete statistics of the corpus are presented in Table \ref{tab:cstats}.
%% \todo{I wonder if we need the full table. It may be enough to say the number of sentences and extractions in the text, and possibly of predicates, without the split, as we gave up on the domain portability. Also, the number of questions isn't explained anyhow, so in any case need to take it out.}

In addition to presenting this first corpus, they automatically tested the performance of various prominent
Open IE systems on it. While there are many extrinsic uses for Open IE, this
constituted the first \emph{intrinsic} comparison.
In particular, that study found that the best performing systems - Open IE4, ClausIE, and PropS - 
offered different trade-offs between precision and recall, as shown in Figure \ref{fig:prop} (based on the confidence scores, as assigned by the systems).

We extend upon this line of work by presenting the first
supervised Open IE extractor trained on
this large recent corpus.
%\todo{can we just say we're the first supervised, or is "fully" needed?}
Further leveraging the inter-relation between SRL and Open IE, we take  a state of the art SRL deep learning model as our starting point,
while modifying and extending it to fit the Open IE task.


%% Traditionally, the  formal definition of Open IE was somewhat lacking and predominantly defined by its different
%% However, several independent recent efforts have tried to formalize the desired requirements from Open IE extractions
%% \cite{bhutani2016nested,Stanovsky2016EMNLP}.
%% Consolidating their findings, we can sum the principles as the following:

%% (1) \emph{Completeness and open lexicon} - Open IE systems aim to extract all asserted propositions from a sentence,
%% %In practice, most current Open IE systems limit their scope to extracting verbal predicates, but consider all possible verbs without being bound to a pre-specified lexicon.
%% (2) \emph{Assertedness} -  Extracted propositions should be asserted by the 
%% original sentence.
%% For example, given the sentence \sent{Sam succeeded in convincing John}, ReVerb and ClausIE produce the extraction: \extraction{Sam}{succeeded in convincing}{John}.
%% %% Most Open IE systems do not attempt to recover implied embedded propositions (e.g., \extraction{(Sam; \pred{convinced}; John)}), but rather include matrix verbs (e.g., \pred{succeeded}) in the predicate slot.
%% %% Other elements that affect assertedness, like negations and modals, are typically included in the predicate slot as well (e.g. \extraction{(John; \pred{could not join}; the band)}).
%% Finally, (3) \emph {Minimal propositions}
%% Open IE systems aim to "break down" a sentence into a set of small isolated propositions.
%% For example, this leads to splitting distributive coordination in the sentence \sent{Bell distributes electronic and building products}, for which ClausIE produces: \extraction{Bell}{distributes}{electronic products} and
%% \extraction{Bell}{distributes}{building products}.
%% %Having shorter entities as Open IE arguments was further found to be useful in several semantic tasks \cite{2015angeli-openie,2015stanovsky}.


%% \begin{itemize}
%% \item briefly describe the most prominent \oie\ systems in recent years, giving special attention to the training
%%   signals used in these systems (Previous techniques used mainly unsupervised methods.
%% Emphesize the small number of approaches which attempted to use supervised algorithms)
%% \item Focus on the approach.
%% \end{itemize}
%% Since the introduction of the task, quite a few systems were developed to address it, following the OIE principles above with many of them being publicly available.

%% With the lack of annotated corpora, the most common approach was rule based,
%% applied as post processing over the output of an underlying standard natural language pipeline.


%% Recently, first comparable intrinsic evaluation
%% (forward reference to figure (mark RNN-IE as (this paper))).

%% The best performing systems (OIE4, PropS and ClausIE) achieve different 
%% trade-offs, OIE4 best precision and lower recall, ...

%% Say something about their performance (lacking in recall).

%% Utilizing the new corpus we show how supervised approach can utilize the 
%% recent ML techniques.


%% \subsection{Transducer LSTM}
%% LSTM transducers \cite{graves2012sequence} are a variant of LSTM recurrent networks in which
%% the network produces an output prediction per input token in the sequence.
%% This is different from acceptor RNNs which produce a single prediction for each sentence
%% (for example, for sentiment analysis task \cite{sentimentrnn})
%% and from sequence-to-sequence RNN's which produce an arbitrary number of prediction given an input sequence
%% (an prototypical example being machine translation \cite{mtrnn}).
%% See \cite{goldberg2015primer} for a recent survey of the usage of these models in NLP.

%% Recurrent Neural Networks (RNNs). This approach was proven to be effective in many
%% recent NLP papers.
%% For a recent and extensive survey of RNNs in NLP see \cite{goldberg2015primer}.

%% Specifically, we use a
%% bi-directional LSTM transducer  which
%% outputs a probability distribution over the three possible labels (B,
%% I, and O) per word, taking into account arbitrary length contexts from
%% both past as well as future words.

%% \begin{table}
%% \begin{tabular}{|lr|}
%% \hline
%% \textbf{\#Sentences}   & 3200            \\
%% \textbf{\#Predicates}  & 7710            \\
%% \textbf{\#Extractions} & \textbf{10359}  \\
%% \end{tabular}
			        %% \caption{Corpus statistics.}
   				%%    \label{tab:cstats}
%%\end{table}
